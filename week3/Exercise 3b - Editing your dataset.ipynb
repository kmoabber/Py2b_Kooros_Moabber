{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6f4f9a",
   "metadata": {},
   "source": [
    "<div style=\"background: black; padding: 10px 250px\"><img src=\"https://www.veldikompetens.se/wp-content/themes/consid/static/icons/VeldiKompetens_Logo_Web_Negative.svg\" title=\"Veldi kompetens\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93bffd",
   "metadata": {},
   "source": [
    "<hr><h1><center>Exercise 3b - Editing and updating your dataset</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa6de2",
   "metadata": {},
   "source": [
    "<h3>Instructions </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add1cd83",
   "metadata": {},
   "source": [
    "<p>In this exercise you will learn more about editing and updating your dataset and we will also perform operations such as cleaning and removing data. We will also get a better overview of the dataset we are working with.  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32acb796",
   "metadata": {},
   "source": [
    "<h3> 1. Setup </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b95b4a",
   "metadata": {},
   "source": [
    "Authors note: I actually encountered a very interesting issue initially working with this dataset. Pandas has a standard of setting empty inputs in the csv file to NaN (Not a Number) and is the traditional approach of working with missing data. If something is missing by default set it to NaN. However! if you remove the na_values below you will see that bean type is still just an empty string. To fix this I started by reseraching into the csv file and found that instead of the usual format col1val,col2val,col3val,,col5val where there is nothing between col3 and col5 there was instead a blank space i.e col3, ,col5. Upon further examining what this blank space represented it appears to be a special type of encoding for blankspaces namely \\xao0 (read some about it if you want to! Very interesting issue.) It can however be solved with the na_values parameter below. This is how it is working with data in real life! Things are never perfect:)\n",
    "\n",
    "(na_values is a parameter that tells pandas what to identify as NaN values)\n",
    "\n",
    "Neccesary libraries and the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3b14d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company(Maker-if known)</th>\n",
       "      <th>Specific Bean Origin or Bar Name</th>\n",
       "      <th>REF</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Cocoa Percent</th>\n",
       "      <th>Company Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Bean Type</th>\n",
       "      <th>Broad Bean Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>63%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sao Tome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Peru</td>\n",
       "      <td>647.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>70%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Congo</td>\n",
       "      <td>749.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>65%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Forastero</td>\n",
       "      <td>Congo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>749.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>65%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Forastero</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>781.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>62%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Brazil, Mitzi Blue</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>65%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1799 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company(Maker-if known)  Specific Bean Origin or Bar Name     REF  \\\n",
       "0                   A. Morin                       Agua Grande  1876.0   \n",
       "1                   A. Morin                             Kpime  1676.0   \n",
       "2                   A. Morin                            Atsane  1676.0   \n",
       "3                   A. Morin                             Akata  1680.0   \n",
       "4                   A. Morin                            Quilla  1704.0   \n",
       "...                      ...                               ...     ...   \n",
       "1794                  Zotter                              Peru   647.0   \n",
       "1795                  Zotter                             Congo   749.0   \n",
       "1796                  Zotter                      Kerala State   749.0   \n",
       "1797                  Zotter                      Kerala State   781.0   \n",
       "1798                  Zotter                Brazil, Mitzi Blue   486.0   \n",
       "\n",
       "      Review Date Cocoa Percent Company Location  Rating  Bean Type  \\\n",
       "0          2016.0           63%           France    3.75        NaN   \n",
       "1          2015.0           70%           France    2.75        NaN   \n",
       "2          2015.0           70%           France    3.00        NaN   \n",
       "3          2015.0           70%           France    3.50        NaN   \n",
       "4          2015.0           70%           France    3.50        NaN   \n",
       "...           ...           ...              ...     ...        ...   \n",
       "1794       2011.0           70%          Austria    3.75        NaN   \n",
       "1795       2011.0           65%          Austria    3.00  Forastero   \n",
       "1796       2011.0           65%          Austria    3.50  Forastero   \n",
       "1797       2011.0           62%          Austria    3.25        NaN   \n",
       "1798       2010.0           65%          Austria    3.00        NaN   \n",
       "\n",
       "     Broad Bean Origin  \n",
       "0             Sao Tome  \n",
       "1                 Togo  \n",
       "2                 Togo  \n",
       "3                 Togo  \n",
       "4                 Peru  \n",
       "...                ...  \n",
       "1794              Peru  \n",
       "1795             Congo  \n",
       "1796             India  \n",
       "1797             India  \n",
       "1798            Brazil  \n",
       "\n",
       "[1799 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Remeber you need to have the file accessible locally\n",
    "df = pd.read_csv(\"flavors_of_cacao.csv\", na_values = [\" \", u'\\xa0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d44b12",
   "metadata": {},
   "source": [
    "<h3> 2. Examining our data</h3>\n",
    "<h4> 2.1 Cleaning the data </h4>\n",
    "<p>As can be seen in the bean type column there are missing values, logically this seems odd right? It might be considered an important column for possible evaluations on what gives a particular chocolate a good rating. Further discussion on this topic will be presented in exercise 3b, but for now  we are going to work with something called cleaning data and how we can do it in pandas. Essentially cleaning data is removing invalid samples from the dataset and the goal of cleaning data can be summarized as achieving the points below. </p>\n",
    "<ul>\n",
    "    <li>Is there any row that has no value in any column but still exist as an entry? If so delete.</li>\n",
    "    <li>Remove samples which are extreme outliers and does not really make any logical sense</li>\n",
    "    <li>Remove duplicates (Of course depends on data, sometimes duplicates are part of the structure)</li>\n",
    "</ul>\n",
    "<p> Lets check out the bean type column which from the getgo seems pretty scarce in data  and evaluate how many of the samples have NaN values</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50fbbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful things to have access to\n",
    "samples = len(df)\n",
    "columns = len(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897de0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Whilst you definitely can do a forloop use pandas/numpy instead! They are much faster and a better practice\n",
    "bean_col = df[\"Bean Type\"]\n",
    "samples_missing_bean = bean_col.isna().sum()\n",
    "\n",
    "print(f\"Samples missing bean type value: {samples_missing_bean/samples * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a24b8",
   "metadata": {},
   "source": [
    "Actually, lets perform this check for our entire dataset, just to get a better feel for the data. Usually you would do this much smoother and print less, but for educations sake we go with the more pedalogical approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nan():\n",
    "\n",
    "    for col in df.columns:\n",
    "        column_name = col\n",
    "        working_col = df[col]\n",
    "    \n",
    "        working_col_missing_bean = working_col.isna().sum()\n",
    "    \n",
    "        print(f\"The column {column_name} is missing {working_col_missing_bean/samples * 100}% of data! \")\n",
    "        \n",
    "count_nan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b5035",
   "metadata": {},
   "source": [
    "Incredible how we could get so much information so quickly right? Lets do some more digging.\n",
    "\n",
    "Lets wait a bit with reasoning about the huge lack of information about bean type, for now lets check if there are rows that are entirely empty and remove those by the looks of it there might be some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3830ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might seem a bit magical, break it down into several lines if you wish!\n",
    "# Essentially df.isna() checks if there is a NaN value and .all(axis=1) checks if this is true in each column!\n",
    "nan_samples = df[df.isna().all(axis=1)]\n",
    "nan_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72920f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets go about removing these instances as they only corrupt the data, notice the indexes are still the same as in the original\n",
    "nan_indexes = nan_samples.index.values\n",
    "nan_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets remove these from the original\n",
    "df = df.drop(nan_indexes)\n",
    "count_nan()\n",
    "\n",
    "# Note: The above example is a more handson approach, pandas has a builtin-functionality for the same purpose;\n",
    "# df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1812e97",
   "metadata": {},
   "source": [
    "Awesome! Now lets check for duplicates, pandas has a neat functionality builtin which is called duplicated()\n",
    "duplicated returns a pandas series with boolean values of true/false if there is more than one occurence of an identical sample. To create a \"new\" dataframe with only the duplicated values you do as we did above by saying df[]. It creates a new dataframe with only the true values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to show\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72e2ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duplicate_indexes = df[df.duplicated()].index\n",
    "df = df.drop(duplicate_indexes)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly after having removed samples you usually re-index the dataset before proceeding and lets save our edited dataset\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(\"edited_choco.csv\", index=False)\n",
    "#In Pandas there is also a way of counting duplicates which may be very relevant for our case since we have a lot of duplicates in terms of companies lets examine this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55172d",
   "metadata": {},
   "source": [
    "In Pandas there is also a way of counting duplicates which may be very relevant for our case since we have a lot of duplicates in terms of for example companies lets examine this. In the below code the functionality pivot_table can be used to output a table of the desired readings, you can do a lot of awesome stuff with this function but this is the most simple example. aggfunc is used to describe what action you want to perform on the column, with \"size\" being a keyword for counting duplicates. NOTE; NaN values are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0065155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(columns=[\"Rating\"], aggfunc=\"size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a32b7",
   "metadata": {},
   "source": [
    "<h4>2.3 Time for some Q/A! </h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da3f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Drop the below sample from the table it is enough to check that there is one less sample than the code above\n",
    "drop_index = 394\n",
    "#TODO; no need to reassign the updated value to the df.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d9dd64",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "<div class=\"output_subarea output_html rendered_html output_result\" dir=\"auto\"><div>\n",
    "<style scoped=\"\">\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Company(Maker-if known)</th>\n",
    "      <th>Specific Bean Origin or Bar Name</th>\n",
    "      <th>REF</th>\n",
    "      <th>Review Date</th>\n",
    "      <th>Cocoa Percent</th>\n",
    "      <th>Company Location</th>\n",
    "      <th>Rating</th>\n",
    "      <th>Bean Type</th>\n",
    "      <th>Broad Bean Origin</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>A. Morin</td>\n",
    "      <td>Agua Grande</td>\n",
    "      <td>1876.0</td>\n",
    "      <td>2016.0</td>\n",
    "      <td>63%</td>\n",
    "      <td>France</td>\n",
    "      <td>3.75</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Sao Tome</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>A. Morin</td>\n",
    "      <td>Kpime</td>\n",
    "      <td>1676.0</td>\n",
    "      <td>2015.0</td>\n",
    "      <td>70%</td>\n",
    "      <td>France</td>\n",
    "      <td>2.75</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Togo</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>A. Morin</td>\n",
    "      <td>Atsane</td>\n",
    "      <td>1676.0</td>\n",
    "      <td>2015.0</td>\n",
    "      <td>70%</td>\n",
    "      <td>France</td>\n",
    "      <td>3.00</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Togo</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>A. Morin</td>\n",
    "      <td>Akata</td>\n",
    "      <td>1680.0</td>\n",
    "      <td>2015.0</td>\n",
    "      <td>70%</td>\n",
    "      <td>France</td>\n",
    "      <td>3.50</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Togo</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>A. Morin</td>\n",
    "      <td>Quilla</td>\n",
    "      <td>1704.0</td>\n",
    "      <td>2015.0</td>\n",
    "      <td>70%</td>\n",
    "      <td>France</td>\n",
    "      <td>3.50</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Peru</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>...</th>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1790</th>\n",
    "      <td>Zotter</td>\n",
    "      <td>Peru</td>\n",
    "      <td>647.0</td>\n",
    "      <td>2011.0</td>\n",
    "      <td>70%</td>\n",
    "      <td>Austria</td>\n",
    "      <td>3.75</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Peru</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1791</th>\n",
    "      <td>Zotter</td>\n",
    "      <td>Congo</td>\n",
    "      <td>749.0</td>\n",
    "      <td>2011.0</td>\n",
    "      <td>65%</td>\n",
    "      <td>Austria</td>\n",
    "      <td>3.00</td>\n",
    "      <td>Forastero</td>\n",
    "      <td>Congo</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1792</th>\n",
    "      <td>Zotter</td>\n",
    "      <td>Kerala State</td>\n",
    "      <td>749.0</td>\n",
    "      <td>2011.0</td>\n",
    "      <td>65%</td>\n",
    "      <td>Austria</td>\n",
    "      <td>3.50</td>\n",
    "      <td>Forastero</td>\n",
    "      <td>India</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1793</th>\n",
    "      <td>Zotter</td>\n",
    "      <td>Kerala State</td>\n",
    "      <td>781.0</td>\n",
    "      <td>2011.0</td>\n",
    "      <td>62%</td>\n",
    "      <td>Austria</td>\n",
    "      <td>3.25</td>\n",
    "      <td>NaN</td>\n",
    "      <td>India</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1794</th>\n",
    "      <td>Zotter</td>\n",
    "      <td>Brazil, Mitzi Blue</td>\n",
    "      <td>486.0</td>\n",
    "      <td>2010.0</td>\n",
    "      <td>65%</td>\n",
    "      <td>Austria</td>\n",
    "      <td>3.00</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Brazil</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "<p>1794 rows Ã— 9 columns</p>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2 Output the amount of duplicates in the company location\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271abc9",
   "metadata": {},
   "source": [
    "Expected output: \n",
    "<pre>Company Location\n",
    "Amsterdam              4\n",
    "Argentina              9\n",
    "Australia             49\n",
    "Austria               26\n",
    "Belgium               40\n",
    "Bolivia                2\n",
    "Brazil                17\n",
    "Canada               125\n",
    "Chile                  2\n",
    "Colombia              23\n",
    "Costa Rica             9\n",
    "Czech Republic         1\n",
    "Denmark               15\n",
    "Domincan Republic      5\n",
    "Ecuador               54\n",
    "Eucador                1\n",
    "Fiji                   4\n",
    "Finland                2\n",
    "France               156\n",
    "Germany               35\n",
    "Ghana                  1\n",
    "Grenada                3\n",
    "Guatemala             10\n",
    "Honduras               6\n",
    "Hungary               22\n",
    "Iceland                3\n",
    "India                  1\n",
    "Ireland                4\n",
    "Israel                 9\n",
    "Italy                 63\n",
    "Japan                 17\n",
    "Lithuania              6\n",
    "Madagascar            17\n",
    "Martinique             1\n",
    "Mexico                 4\n",
    "Netherlands            4\n",
    "New Zealand           17\n",
    "Niacragua              1\n",
    "Nicaragua              5\n",
    "Peru                  17\n",
    "Philippines            1\n",
    "Poland                 8\n",
    "Portugal               3\n",
    "Puerto Rico            4\n",
    "Russia                 1\n",
    "Sao Tome               4\n",
    "Scotland              10\n",
    "Singapore              3\n",
    "South Africa           3\n",
    "South Korea            5\n",
    "Spain                 25\n",
    "St. Lucia              2\n",
    "Suriname               1\n",
    "Sweden                 5\n",
    "Switzerland           38\n",
    "U.K.                  96\n",
    "U.S.A.               764\n",
    "Venezuela             20\n",
    "Vietnam               11\n",
    "Wales                  1\n",
    "dtype: int64</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69faf61",
   "metadata": {},
   "source": [
    "Thats it for this exercise! In the next exercise we will tackle some other problems related to transforming our data types, noramlizing values and reason a bit about the almost 50% missing bean types:) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd5b22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
